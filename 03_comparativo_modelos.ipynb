{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comparação de Modelos Clássicos\n",
        "\n",
        "Este notebook executa diversos algoritmos clássicos de classificação utilizando as features clássicas combinadas às features quânticas previstas pela rede neural profunda. O objetivo é verificar quais modelos se beneficiam do conjunto expandido de atributos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dependências\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import math\n",
        "from typing import List, Optional, Sequence\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from IPython.display import display\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.base import clone\n",
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    balanced_accuracy_score,\n",
        "    f1_score,\n",
        "    mean_absolute_error,\n",
        "    mean_squared_error,\n",
        "    precision_score,\n",
        "    r2_score,\n",
        "    recall_score,\n",
        "    roc_auc_score,\n",
        ")\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Estilo padrão para gráficos\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams.update({\"figure.figsize\": (10, 5), \"axes.titlesize\": 14, \"axes.labelsize\": 12})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Carregamento dos dados\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "data_dir = Path(\"features\")\n",
        "fold_paths = sorted(data_dir.glob(\"features_y_fold*.csv\"))\n",
        "if not fold_paths:\n",
        "    raise FileNotFoundError(\"Nenhum arquivo `features_y_fold*.csv` foi encontrado na pasta `features/`.\")\n",
        "\n",
        "fold_frames = []\n",
        "for path in fold_paths:\n",
        "    frame = pd.read_csv(path)\n",
        "    frame[\"fold_name\"] = path.stem\n",
        "    fold_frames.append(frame)\n",
        "\n",
        "fold_summary = (\n",
        "    pd.concat(\n",
        "        [df.assign(set=df[\"set\"].str.lower())[[\"fold\", \"fold_name\", \"set\"]] for df in fold_frames],\n",
        "        ignore_index=True,\n",
        "    )\n",
        "    .value_counts()\n",
        "    .unstack(fill_value=0)\n",
        ")\n",
        "fold_summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparação das features\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "classical_features = [col for col in fold_frames[0].columns if col.startswith(\"class_\")]\n",
        "quantum_features = [col for col in fold_frames[0].columns if col.startswith(\"qf_\")]\n",
        "\n",
        "metric_functions = {\n",
        "    \"AUC\": lambda y_true, y_score, y_pred: roc_auc_score(y_true, y_score) if len(np.unique(y_true)) > 1 else np.nan,\n",
        "    \"F1 Score Overall\": lambda y_true, y_score, y_pred: f1_score(y_true, y_pred),\n",
        "    \"Balanced Accuracy\": lambda y_true, y_score, y_pred: balanced_accuracy_score(y_true, y_pred),\n",
        "    \"Precision Class 0\": lambda y_true, y_score, y_pred: precision_score(y_true, y_pred, pos_label=0),\n",
        "    \"Precision Class 1\": lambda y_true, y_score, y_pred: precision_score(y_true, y_pred, pos_label=1),\n",
        "    \"Recall Class 0\": lambda y_true, y_score, y_pred: recall_score(y_true, y_pred, pos_label=0),\n",
        "    \"Recall Class 1\": lambda y_true, y_score, y_pred: recall_score(y_true, y_pred, pos_label=1),\n",
        "}\n",
        "\n",
        "# Rede neural para prever as features quânticas\n",
        "class DeepNumpyMLPRegressor:\n",
        "    \"\"\"Implementação simples de um MLP com ReLU e optimização Adam.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_layers: Sequence[int] = (256, 128, 64),\n",
        "        learning_rate: float = 1e-3,\n",
        "        epochs: int = 100,\n",
        "        batch_size: int = 256,\n",
        "        random_state: Optional[int] = 42,\n",
        "        beta1: float = 0.9,\n",
        "        beta2: float = 0.999,\n",
        "        eps: float = 1e-8,\n",
        "    ) -> None:\n",
        "        self.hidden_layers = tuple(hidden_layers)\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.random_state = random_state\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        self.eps = eps\n",
        "        self.weights: List[np.ndarray] = []\n",
        "        self.biases: List[np.ndarray] = []\n",
        "        self.m_w: List[np.ndarray] = []\n",
        "        self.v_w: List[np.ndarray] = []\n",
        "        self.m_b: List[np.ndarray] = []\n",
        "        self.v_b: List[np.ndarray] = []\n",
        "        self._step = 0\n",
        "\n",
        "    def _initialise(self, n_features: int, n_outputs: int) -> None:\n",
        "        layer_sizes = [n_features, *self.hidden_layers, n_outputs]\n",
        "        rng = np.random.default_rng(self.random_state)\n",
        "        self.weights.clear()\n",
        "        self.biases.clear()\n",
        "        self.m_w.clear()\n",
        "        self.v_w.clear()\n",
        "        self.m_b.clear()\n",
        "        self.v_b.clear()\n",
        "        for in_dim, out_dim in zip(layer_sizes[:-1], layer_sizes[1:]):\n",
        "            limit = math.sqrt(6.0 / (in_dim + out_dim))\n",
        "            weight = rng.uniform(-limit, limit, size=(in_dim, out_dim)).astype(np.float64)\n",
        "            bias = np.zeros(out_dim, dtype=np.float64)\n",
        "            self.weights.append(weight)\n",
        "            self.biases.append(bias)\n",
        "            self.m_w.append(np.zeros_like(weight))\n",
        "            self.v_w.append(np.zeros_like(weight))\n",
        "            self.m_b.append(np.zeros_like(bias))\n",
        "            self.v_b.append(np.zeros_like(bias))\n",
        "        self._step = 0\n",
        "\n",
        "    @staticmethod\n",
        "    def _relu(values: np.ndarray) -> np.ndarray:\n",
        "        return np.maximum(0.0, values)\n",
        "\n",
        "    @staticmethod\n",
        "    def _relu_grad(values: np.ndarray) -> np.ndarray:\n",
        "        grad = np.zeros_like(values)\n",
        "        grad[values > 0.0] = 1.0\n",
        "        return grad\n",
        "\n",
        "    def _forward(self, batch: np.ndarray):\n",
        "        activations = [batch]\n",
        "        pre_activations: List[np.ndarray] = []\n",
        "        current = batch\n",
        "        for idx, (weight, bias) in enumerate(zip(self.weights, self.biases)):\n",
        "            linear = current @ weight + bias\n",
        "            pre_activations.append(linear)\n",
        "            if idx == len(self.weights) - 1:\n",
        "                current = linear\n",
        "            else:\n",
        "                current = self._relu(linear)\n",
        "            activations.append(current)\n",
        "        return pre_activations, activations\n",
        "\n",
        "    def _adam_step(self, grads_w: List[np.ndarray], grads_b: List[np.ndarray]) -> None:\n",
        "        self._step += 1\n",
        "        lr = self.learning_rate\n",
        "        for idx, (grad_w, grad_b) in enumerate(zip(grads_w, grads_b)):\n",
        "            self.m_w[idx] = self.beta1 * self.m_w[idx] + (1 - self.beta1) * grad_w\n",
        "            self.v_w[idx] = self.beta2 * self.v_w[idx] + (1 - self.beta2) * (grad_w ** 2)\n",
        "            self.m_b[idx] = self.beta1 * self.m_b[idx] + (1 - self.beta1) * grad_b\n",
        "            self.v_b[idx] = self.beta2 * self.v_b[idx] + (1 - self.beta2) * (grad_b ** 2)\n",
        "            m_hat_w = self.m_w[idx] / (1 - self.beta1 ** self._step)\n",
        "            v_hat_w = self.v_w[idx] / (1 - self.beta2 ** self._step)\n",
        "            m_hat_b = self.m_b[idx] / (1 - self.beta1 ** self._step)\n",
        "            v_hat_b = self.v_b[idx] / (1 - self.beta2 ** self._step)\n",
        "            self.weights[idx] -= lr * m_hat_w / (np.sqrt(v_hat_w) + self.eps)\n",
        "            self.biases[idx] -= lr * m_hat_b / (np.sqrt(v_hat_b) + self.eps)\n",
        "\n",
        "    def fit(self, features: np.ndarray, targets: np.ndarray) -> None:\n",
        "        features = np.asarray(features, dtype=np.float64)\n",
        "        targets = np.asarray(targets, dtype=np.float64)\n",
        "        if features.ndim != 2:\n",
        "            raise ValueError('As features devem ser uma matriz 2D.')\n",
        "        if targets.ndim != 2:\n",
        "            raise ValueError('Os alvos devem ser uma matriz 2D.')\n",
        "        self._initialise(features.shape[1], targets.shape[1])\n",
        "        rng = np.random.default_rng(self.random_state)\n",
        "        n_samples = features.shape[0]\n",
        "        indices = np.arange(n_samples)\n",
        "        for epoch in range(1, self.epochs + 1):\n",
        "            rng.shuffle(indices)\n",
        "            batches = [indices[i:i + self.batch_size] for i in range(0, n_samples, self.batch_size)]\n",
        "            for batch_indices in batches:\n",
        "                batch_features = features[batch_indices]\n",
        "                batch_targets = targets[batch_indices]\n",
        "                pre_acts, activations = self._forward(batch_features)\n",
        "                predictions = activations[-1]\n",
        "                errors = predictions - batch_targets\n",
        "                grads_w: List[np.ndarray] = [np.zeros_like(w) for w in self.weights]\n",
        "                grads_b: List[np.ndarray] = [np.zeros_like(b) for b in self.biases]\n",
        "                delta = 2.0 * errors / batch_features.shape[0]\n",
        "                for layer_idx in reversed(range(len(self.weights))):\n",
        "                    grads_w[layer_idx] = activations[layer_idx].T @ delta\n",
        "                    grads_b[layer_idx] = np.sum(delta, axis=0)\n",
        "                    if layer_idx > 0:\n",
        "                        delta = (delta @ self.weights[layer_idx].T) * self._relu_grad(pre_acts[layer_idx - 1])\n",
        "                self._adam_step(grads_w, grads_b)\n",
        "\n",
        "    def predict(self, features: np.ndarray) -> np.ndarray:\n",
        "        features = np.asarray(features, dtype=np.float64)\n",
        "        _, activations = self._forward(features)\n",
        "        return activations[-1]\n",
        "\n",
        "dl_predicted_quantum_features = [f'dl_pred_{feature}' for feature in quantum_features]\n",
        "for fold_df in fold_frames:\n",
        "    train_mask = fold_df[\"set\"] == \"train\"\n",
        "    regressor = DeepNumpyMLPRegressor(epochs=150, learning_rate=5e-4, batch_size=128, hidden_layers=(256, 128, 64))\n",
        "    regressor.fit(\n",
        "        fold_df.loc[train_mask, classical_features].values,\n",
        "        fold_df.loc[train_mask, quantum_features].values,\n",
        "    )\n",
        "    predicted_values = regressor.predict(fold_df[classical_features].values)\n",
        "    for column_name, column_values in zip(dl_predicted_quantum_features, predicted_values.T):\n",
        "        fold_df[column_name] = column_values\n",
        "\n",
        "dl_feature_set = classical_features + dl_predicted_quantum_features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Avaliação dos algoritmos\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "algorithm_estimators = {\n",
        "    \"Logistic Regression\": Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"model\", LogisticRegression(max_iter=1000, random_state=42)),\n",
        "    ]),\n",
        "    \"KNN (k=15)\": Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"model\", KNeighborsClassifier(n_neighbors=15)),\n",
        "    ]),\n",
        "    \"SVM (RBF)\": Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"model\", SVC(kernel=\"rbf\", probability=True, random_state=42)),\n",
        "    ]),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=300, random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
        "    \"MLP Classifier\": Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"model\", MLPClassifier(hidden_layer_sizes=(256, 128, 64), max_iter=400, random_state=42)),\n",
        "    ]),\n",
        "}\n",
        "\n",
        "comparison_results = []\n",
        "comparison_predictions = []\n",
        "for algorithm_name, estimator in algorithm_estimators.items():\n",
        "    for fold_idx, fold_df in enumerate(fold_frames):\n",
        "        train_df = fold_df[fold_df['set'] == 'train']\n",
        "        test_df = fold_df[fold_df['set'] == 'test']\n",
        "        X_train = train_df[dl_feature_set]\n",
        "        X_test = test_df[dl_feature_set]\n",
        "        y_train = train_df['y']\n",
        "        y_test = test_df['y']\n",
        "\n",
        "        model = clone(estimator)\n",
        "        model.fit(X_train, y_train)\n",
        "        if hasattr(model, 'predict_proba'):\n",
        "            y_proba = model.predict_proba(X_test)[:, 1]\n",
        "        else:\n",
        "            decision = model.decision_function(X_test)\n",
        "            y_proba = (decision - decision.min()) / (decision.max() - decision.min() + 1e-9)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        for metric_name, metric_fn in metric_functions.items():\n",
        "            value = metric_fn(y_test, y_proba, y_pred)\n",
        "            comparison_results.append({\n",
        "                'fold': fold_idx,\n",
        "                'fold_name': fold_df['fold_name'].iat[0],\n",
        "                'algorithm': algorithm_name,\n",
        "                'metric': metric_name,\n",
        "                'value': value,\n",
        "            })\n",
        "\n",
        "        comparison_predictions.append(pd.DataFrame({\n",
        "            'fold': fold_idx,\n",
        "            'fold_name': fold_df['fold_name'].iat[0],\n",
        "            'row_id': test_df['row_id'].values,\n",
        "            'algorithm': algorithm_name,\n",
        "            'y_true': y_test.values,\n",
        "            'y_pred': y_pred,\n",
        "            'y_proba': y_proba,\n",
        "        }))\n",
        "\n",
        "comparison_results_df = pd.DataFrame(comparison_results)\n",
        "comparison_predictions_df = pd.concat(comparison_predictions, ignore_index=True)\n",
        "comparison_results_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Métricas agregadas\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "comparison_summary = (\n",
        "    comparison_results_df\n",
        "    .groupby(['algorithm', 'metric'])['value']\n",
        "    .agg(\n",
        "        median=lambda s: np.nanmedian(s),\n",
        "        q1=lambda s: np.nanquantile(s, 0.25),\n",
        "        q3=lambda s: np.nanquantile(s, 0.75),\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "comparison_summary['iqr'] = comparison_summary['q3'] - comparison_summary['q1']\n",
        "comparison_summary['median_iqr'] = comparison_summary.apply(\n",
        "    lambda row: f\"{row['median']:.3f} (IQR: {row['q1']:.3f}-{row['q3']:.3f})\",\n",
        "    axis=1\n",
        ")\n",
        "comparison_summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparação visual\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "metric_order = [\n",
        "    'AUC',\n",
        "    'F1 Score Overall',\n",
        "    'Balanced Accuracy',\n",
        "    'Precision Class 0',\n",
        "    'Precision Class 1',\n",
        "    'Recall Class 0',\n",
        "    'Recall Class 1',\n",
        "]\n",
        "plot_ready = (\n",
        "    comparison_summary\n",
        "    .pivot(index='metric', columns='algorithm', values='median')\n",
        "    .reindex(metric_order)\n",
        ")\n",
        "ax = plot_ready.plot(kind='bar', figsize=(14, 6))\n",
        "ax.set_ylabel('Mediana por fold')\n",
        "ax.set_xlabel('Métrica')\n",
        "ax.set_title('Desempenho por algoritmo com features expandidas')\n",
        "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
        "ax.legend(loc='upper right', ncol=2)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}