{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predi\u00e7\u00e3o com HistGradientBoostingRegressor\n",
    "\n",
    "Este notebook carrega os *folds* dispon\u00edveis na pasta `features/`, treina modelos de Gradient Boosting usando apenas as features cl\u00e1ssicas (`class_0` a `class_12`) e o conjunto combinado de features cl\u00e1ssicas + qu\u00e2nticas (`qf_0` a `qf_12`).\n",
    "\n",
    "Al\u00e9m disso, inclu\u00edmos um `HistGradientBoostingRegressor` para aproximar as features qu\u00e2nticas a partir das cl\u00e1ssicas e avaliamos o impacto dessas estimativas no desempenho do classificador.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depend\u00eancias\n",
    "\n",
    "O notebook utiliza `pandas`, `numpy`, `scikit-learn`, `matplotlib` e `seaborn`. Caso ainda n\u00e3o as tenha instalado no seu ambiente, execute o comando abaixo em uma c\u00e9lula separada ou diretamente no terminal:\n",
    "\n",
    "```bash\n",
    "pip install pandas numpy scikit-learn matplotlib seaborn\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score,\n",
    "    f1_score,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    precision_score,\n",
    "    r2_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# Configura\u00e7\u00e3o est\u00e9tica padr\u00e3o para os gr\u00e1ficos\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams.update({\"figure.figsize\": (10, 5), \"axes.titlesize\": 14, \"axes.labelsize\": 12})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento dos dados\n",
    "\n",
    "Cada CSV em `features/` corresponde a um *fold*. O conjunto possui uma coluna `set` indicando se a amostra pertence ao treino ou ao teste.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_dir = Path(\"features\")\n",
    "fold_paths = sorted(data_dir.glob(\"features_y_fold*.csv\"))\n",
    "if not fold_paths:\n",
    "    raise FileNotFoundError(\"Nenhum arquivo `features_y_fold*.csv` foi encontrado na pasta `features/`.\")\n",
    "\n",
    "fold_frames = []\n",
    "for path in fold_paths:\n",
    "    frame = pd.read_csv(path)\n",
    "    frame[\"fold_name\"] = path.stem\n",
    "    fold_frames.append(frame)\n",
    "\n",
    "fold_summary = (\n",
    "    pd.concat(\n",
    "        [df.assign(set=df[\"set\"].str.lower())[[\"fold\", \"fold_name\", \"set\"]] for df in fold_frames],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "    .value_counts()\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "fold_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defini\u00e7\u00e3o dos grupos de features e fun\u00e7\u00e3o de avalia\u00e7\u00e3o\n",
    "\n",
    "A fun\u00e7\u00e3o abaixo treina um `GradientBoostingClassifier` para cada conjunto de features em todos os *folds*, calcula as m\u00e9tricas desejadas no conjunto de teste e armazena as predi\u00e7\u00f5es geradas.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "classical_features = [col for col in fold_frames[0].columns if col.startswith(\"class_\")]\n",
    "quantum_features = [col for col in fold_frames[0].columns if col.startswith(\"qf_\")]\n",
    "\n",
    "# Treinamento do regressor qu\u00e2ntico \u00e9 realizado separadamente em cada fold usando apenas os dados de treino\n",
    "predicted_quantum_features = [f\"pred_{feature}\" for feature in quantum_features]\n",
    "\n",
    "for fold_df in fold_frames:\n",
    "    train_mask = fold_df[\"set\"] == \"train\"\n",
    "    fold_regressor = MultiOutputRegressor(\n",
    "        HistGradientBoostingRegressor(random_state=42)\n",
    "    )\n",
    "    fold_regressor.fit(\n",
    "        fold_df.loc[train_mask, classical_features],\n",
    "        fold_df.loc[train_mask, quantum_features],\n",
    "    )\n",
    "    predicted_values = fold_regressor.predict(fold_df[classical_features])\n",
    "    for pred_column, column_values in zip(predicted_quantum_features, predicted_values.T):\n",
    "        fold_df[pred_column] = column_values\n",
    "\n",
    "feature_sets = {\n",
    "    \"Benchmark\": classical_features,\n",
    "    \"Quantum\": classical_features + quantum_features,\n",
    "    \"Quantum (Regressor)\": classical_features + predicted_quantum_features,\n",
    "}\n",
    "\n",
    "metric_functions = {\n",
    "    \"AUC\": lambda y_true, y_score, y_pred: roc_auc_score(y_true, y_score) if len(np.unique(y_true)) > 1 else np.nan,\n",
    "    \"F1 Score Overall\": lambda y_true, y_score, y_pred: f1_score(y_true, y_pred),\n",
    "    \"Balanced Accuracy\": lambda y_true, y_score, y_pred: balanced_accuracy_score(y_true, y_pred),\n",
    "    \"Precision Class 0\": lambda y_true, y_score, y_pred: precision_score(y_true, y_pred, pos_label=0),\n",
    "    \"Precision Class 1\": lambda y_true, y_score, y_pred: precision_score(y_true, y_pred, pos_label=1),\n",
    "    \"Recall Class 0\": lambda y_true, y_score, y_pred: recall_score(y_true, y_pred, pos_label=0),\n",
    "    \"Recall Class 1\": lambda y_true, y_score, y_pred: recall_score(y_true, y_pred, pos_label=1),\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for fold_idx, fold_df in enumerate(fold_frames):\n",
    "    train_df = fold_df[fold_df[\"set\"] == \"train\"]\n",
    "    test_df = fold_df[fold_df[\"set\"] == \"test\"]\n",
    "\n",
    "    y_train = train_df[\"y\"]\n",
    "    y_test = test_df[\"y\"]\n",
    "\n",
    "    for label, columns in feature_sets.items():\n",
    "        X_train = train_df[columns]\n",
    "        X_test = test_df[columns]\n",
    "\n",
    "        model = HistGradientBoostingClassifier(random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        for metric_name, metric_fn in metric_functions.items():\n",
    "            value = metric_fn(y_test, y_proba, y_pred)\n",
    "            results.append(\n",
    "                {\n",
    "                    \"fold\": fold_idx,\n",
    "                    \"fold_name\": fold_df[\"fold_name\"].iat[0],\n",
    "                    \"model\": label,\n",
    "                    \"metric\": metric_name,\n",
    "                    \"value\": value,\n",
    "                }\n",
    "            )\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo das m\u00e9tricas por modelo\n",
    "\n",
    "A tabela a seguir mostra a mediana e o intervalo interquartil (25%-75%) das m\u00e9tricas em todos os *folds*.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "metrics_summary = (\n",
    "    results_df\n",
    "    .groupby(['model', 'metric'])['value']\n",
    "    .agg(\n",
    "        median=lambda s: np.nanmedian(s),\n",
    "        q1=lambda s: np.nanquantile(s, 0.25),\n",
    "        q3=lambda s: np.nanquantile(s, 0.75),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "metrics_summary['iqr'] = metrics_summary['q3'] - metrics_summary['q1']\n",
    "metrics_summary['median_iqr'] = metrics_summary.apply(\n",
    "    lambda row: f\"{row['median']:.4f} [{row['q1']:.4f}, {row['q3']:.4f}]\",\n",
    "    axis=1,\n",
    ")\n",
    "metrics_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gr\u00e1fico comparativo\n",
    "\n",
    "O gr\u00e1fico reproduz o exemplo solicitado, com barras pretas representando o benchmark (apenas features cl\u00e1ssicas) e barras amarelas representando o modelo com features cl\u00e1ssicas + qu\u00e2nticas. Os valores exibidos nas barras correspondem \u00e0s medianas por *fold*.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "metric_order = [\n",
    "    'AUC',\n",
    "    'F1 Score Overall',\n",
    "    'Balanced Accuracy',\n",
    "    'Precision Class 0',\n",
    "    'Precision Class 1',\n",
    "    'Recall Class 0',\n",
    "    'Recall Class 1',\n",
    "]\n",
    "\n",
    "plot_ready = (\n",
    "    metrics_summary\n",
    "    .pivot(index='metric', columns='model', values='median')\n",
    "    .reindex(metric_order)\n",
    ")\n",
    "\n",
    "plot_ready = plot_ready.reindex(columns=[\"Benchmark\", \"Quantum\", \"Quantum (Regressor)\"])\n",
    "\n",
    "model_colors = {\n",
    "    \"Benchmark\": \"#2e2e2e\",\n",
    "    \"Quantum\": \"#f1b82d\",\n",
    "    \"Quantum (Regressor)\": \"#2b8cbe\",\n",
    "}\n",
    "\n",
    "ax = plot_ready.plot(\n",
    "    kind='bar',\n",
    "    color=[model_colors[col] for col in plot_ready.columns],\n",
    "    edgecolor='black'\n",
    ")\n",
    "\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_xlabel('')\n",
    "ax.set_title('Toxicity classification with Gradient Boosting')\n",
    "ax.legend(title='Modelo')\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt='%.2f', label_type='edge', padding=3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Busca de hiperpar\u00e2metros\n",
    "\n",
    "Realizamos uma busca em grade simples para o `HistGradientBoostingClassifier` utilizando o conjunto de features \"Quantum (Regressor)\". Cada combina\u00e7\u00e3o \u00e9 avaliada pela m\u00e9trica de AUC considerando todos os *folds* dispon\u00edveis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_feature_set = \"Quantum (Regressor)\"\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.05, 0.1],\n",
    "    \"max_leaf_nodes\": [31, 63],\n",
    "    \"min_samples_leaf\": [20, 40],\n",
    "    \"max_iter\": [200, 400],\n",
    "}\n",
    "\n",
    "search_results = []\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    fold_scores = []\n",
    "    for fold_df in fold_frames:\n",
    "        train_df = fold_df[fold_df[\"set\"] == \"train\"]\n",
    "        test_df = fold_df[fold_df[\"set\"] == \"test\"]\n",
    "\n",
    "        model = HistGradientBoostingClassifier(random_state=42, **params)\n",
    "        model.fit(train_df[feature_sets[search_feature_set]], train_df[\"y\"])\n",
    "\n",
    "        y_proba = model.predict_proba(test_df[feature_sets[search_feature_set]])[:, 1]\n",
    "        if len(np.unique(test_df[\"y\"])) > 1:\n",
    "            fold_scores.append(roc_auc_score(test_df[\"y\"], y_proba))\n",
    "        else:\n",
    "            fold_scores.append(np.nan)\n",
    "\n",
    "    search_results.append({**params, \"mean_auc\": np.nanmean(fold_scores), \"std_auc\": np.nanstd(fold_scores)})\n",
    "\n",
    "search_results_df = (\n",
    "    pd.DataFrame(search_results)\n",
    "    .sort_values(\"mean_auc\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "search_results_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}