{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predição com GradientBoostingClassifier\n",
    "\n",
    "Este notebook carrega os *folds* disponíveis na pasta `features/`, treina modelos de Gradient Boosting usando apenas as features clássicas (`class_0` a `class_12`) e o conjunto combinado de features clássicas + quânticas (`qf_0` a `qf_12`).\n",
    "\n",
    "Além disso, incluímos um `HistGradientBoostingRegressor` para aproximar as features quânticas a partir das clássicas e avaliamos o impacto dessas estimativas no desempenho do classificador.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependências\n",
    "\n",
    "O notebook utiliza `pandas`, `numpy`, `scikit-learn`, `matplotlib` e `seaborn`. Caso ainda não as tenha instalado no seu ambiente, execute o comando abaixo em uma célula separada ou diretamente no terminal:\n",
    "\n",
    "```bash\n",
    "pip install pandas numpy scikit-learn matplotlib seaborn\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingClassifier, HistGradientBoostingRegressor\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score,\n",
    "    f1_score,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    precision_score,\n",
    "    r2_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# Configuração estética padrão para os gráficos\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams.update({\"figure.figsize\": (10, 5), \"axes.titlesize\": 14, \"axes.labelsize\": 12})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento dos dados\n",
    "\n",
    "Cada CSV em `features/` corresponde a um *fold*. O conjunto possui uma coluna `set` indicando se a amostra pertence ao treino ou ao teste.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_dir = Path(\"features\")\n",
    "fold_paths = sorted(data_dir.glob(\"features_y_fold*.csv\"))\n",
    "if not fold_paths:\n",
    "    raise FileNotFoundError(\"Nenhum arquivo `features_y_fold*.csv` foi encontrado na pasta `features/`.\")\n",
    "\n",
    "fold_frames = []\n",
    "for path in fold_paths:\n",
    "    frame = pd.read_csv(path)\n",
    "    frame[\"fold_name\"] = path.stem\n",
    "    fold_frames.append(frame)\n",
    "\n",
    "fold_summary = (\n",
    "    pd.concat(\n",
    "        [df.assign(set=df[\"set\"].str.lower())[[\"fold\", \"fold_name\", \"set\"]] for df in fold_frames],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "    .value_counts()\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "fold_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição dos grupos de features e função de avaliação\n",
    "\n",
    "A função abaixo treina um `GradientBoostingClassifier` para cada conjunto de features em todos os *folds*, calcula as métricas desejadas no conjunto de teste e armazena as predições geradas.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "classical_features = [col for col in fold_frames[0].columns if col.startswith(\"class_\")]\n",
    "quantum_features = [col for col in fold_frames[0].columns if col.startswith(\"qf_\")]\n",
    "\n",
    "# Treinamento do regressor quântico é realizado separadamente em cada fold usando apenas os dados de treino\n",
    "predicted_quantum_features = [f\"pred_{feature}\" for feature in quantum_features]\n",
    "\n",
    "for fold_df in fold_frames:\n",
    "    train_mask = fold_df[\"set\"] == \"train\"\n",
    "    fold_regressor = MultiOutputRegressor(\n",
    "        HistGradientBoostingRegressor(random_state=42)\n",
    "    )\n",
    "    fold_regressor.fit(\n",
    "        fold_df.loc[train_mask, classical_features],\n",
    "        fold_df.loc[train_mask, quantum_features],\n",
    "    )\n",
    "    predicted_values = fold_regressor.predict(fold_df[classical_features])\n",
    "    for pred_column, column_values in zip(predicted_quantum_features, predicted_values.T):\n",
    "        fold_df[pred_column] = column_values\n",
    "\n",
    "feature_sets = {\n",
    "    \"Benchmark\": classical_features,\n",
    "    \"Quantum\": classical_features + quantum_features,\n",
    "    \"Quantum (Regressor)\": classical_features + predicted_quantum_features,\n",
    "}\n",
    "\n",
    "metric_functions = {\n",
    "    \"AUC\": lambda y_true, y_score, y_pred: roc_auc_score(y_true, y_score) if len(np.unique(y_true)) > 1 else np.nan,\n",
    "    \"F1 Score Overall\": lambda y_true, y_score, y_pred: f1_score(y_true, y_pred),\n",
    "    \"Balanced Accuracy\": lambda y_true, y_score, y_pred: balanced_accuracy_score(y_true, y_pred),\n",
    "    \"Precision Class 0\": lambda y_true, y_score, y_pred: precision_score(y_true, y_pred, pos_label=0),\n",
    "    \"Precision Class 1\": lambda y_true, y_score, y_pred: precision_score(y_true, y_pred, pos_label=1),\n",
    "    \"Recall Class 0\": lambda y_true, y_score, y_pred: recall_score(y_true, y_pred, pos_label=0),\n",
    "    \"Recall Class 1\": lambda y_true, y_score, y_pred: recall_score(y_true, y_pred, pos_label=1),\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for fold_idx, fold_df in enumerate(fold_frames):\n",
    "    train_df = fold_df[fold_df[\"set\"] == \"train\"]\n",
    "    test_df = fold_df[fold_df[\"set\"] == \"test\"]\n",
    "\n",
    "    y_train = train_df[\"y\"]\n",
    "    y_test = test_df[\"y\"]\n",
    "\n",
    "    for label, columns in feature_sets.items():\n",
    "        X_train = train_df[columns]\n",
    "        X_test = test_df[columns]\n",
    "\n",
    "        model = GradientBoostingClassifier(random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        for metric_name, metric_fn in metric_functions.items():\n",
    "            value = metric_fn(y_test, y_proba, y_pred)\n",
    "            results.append(\n",
    "                {\n",
    "                    \"fold\": fold_idx,\n",
    "                    \"fold_name\": fold_df[\"fold_name\"].iat[0],\n",
    "                    \"model\": label,\n",
    "                    \"metric\": metric_name,\n",
    "                    \"value\": value,\n",
    "                }\n",
    "            )\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo das métricas por modelo\n",
    "\n",
    "A tabela a seguir mostra a mediana e o intervalo interquartil (25%-75%) das métricas em todos os *folds*.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "metrics_summary = (\n",
    "    results_df\n",
    "    .groupby(['model', 'metric'])['value']\n",
    "    .agg(\n",
    "        median=lambda s: np.nanmedian(s),\n",
    "        q1=lambda s: np.nanquantile(s, 0.25),\n",
    "        q3=lambda s: np.nanquantile(s, 0.75),\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "metrics_summary['iqr'] = metrics_summary['q3'] - metrics_summary['q1']\n",
    "metrics_summary['median_iqr'] = metrics_summary.apply(\n",
    "    lambda row: f\"{row['median']:.4f} [{row['q1']:.4f}, {row['q3']:.4f}]\",\n",
    "    axis=1,\n",
    ")\n",
    "metrics_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráfico comparativo\n",
    "\n",
    "O gráfico reproduz o exemplo solicitado, com barras pretas representando o benchmark (apenas features clássicas) e barras amarelas representando o modelo com features clássicas + quânticas. Os valores exibidos nas barras correspondem às medianas por *fold*.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "metric_order = [\n",
    "    'AUC',\n",
    "    'F1 Score Overall',\n",
    "    'Balanced Accuracy',\n",
    "    'Precision Class 0',\n",
    "    'Precision Class 1',\n",
    "    'Recall Class 0',\n",
    "    'Recall Class 1',\n",
    "]\n",
    "\n",
    "plot_ready = (\n",
    "    metrics_summary\n",
    "    .pivot(index='metric', columns='model', values='median')\n",
    "    .reindex(metric_order)\n",
    ")\n",
    "\n",
    "plot_ready = plot_ready.reindex(columns=[\"Benchmark\", \"Quantum\", \"Quantum (Regressor)\"])\n",
    "\n",
    "model_colors = {\n",
    "    \"Benchmark\": \"#2e2e2e\",\n",
    "    \"Quantum\": \"#f1b82d\",\n",
    "    \"Quantum (Regressor)\": \"#2b8cbe\",\n",
    "}\n",
    "\n",
    "ax = plot_ready.plot(\n",
    "    kind='bar',\n",
    "    color=[model_colors[col] for col in plot_ready.columns],\n",
    "    edgecolor='black'\n",
    ")\n",
    "\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_xlabel('')\n",
    "ax.set_title('Toxicity classification with Gradient Boosting')\n",
    "ax.legend(title='Modelo')\n",
    "\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt='%.2f', label_type='edge', padding=3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Busca de hiperparâmetros\n",
    "\n",
    "Realizamos uma busca em grade simples para o `HistGradientBoostingRegressor` responsável por aproximar as features quânticas a partir das clássicas. Cada combinação é avaliada pelas métricas de MAE, RMSE e R² considerando todos os *folds* disponíveis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_feature_set = \"Quantum (Regressor)\"\n",
    "regressor_param_grid = {\n",
    "    \"learning_rate\": [0.05, 0.1],\n",
    "    \"max_iter\": [200, 400],\n",
    "    \"max_depth\": [3, 5],\n",
    "    \"min_samples_leaf\": [20, 40],\n",
    "}\n",
    "\n",
    "search_results = []\n",
    "\n",
    "for params in ParameterGrid(regressor_param_grid):\n",
    "    fold_metrics = []\n",
    "    for fold_df in fold_frames:\n",
    "        train_mask = fold_df[\"set\"] == \"train\"\n",
    "        test_mask = fold_df[\"set\"] == \"test\"\n",
    "\n",
    "        base_regressor = HistGradientBoostingRegressor(random_state=42, **params)\n",
    "        regressor = MultiOutputRegressor(base_regressor)\n",
    "        regressor.fit(\n",
    "            fold_df.loc[train_mask, classical_features],\n",
    "            fold_df.loc[train_mask, quantum_features],\n",
    "        )\n",
    "\n",
    "        y_true_quantum = fold_df.loc[test_mask, quantum_features]\n",
    "        y_pred_quantum = regressor.predict(fold_df.loc[test_mask, classical_features])\n",
    "\n",
    "        fold_metrics.append(\n",
    "            {\n",
    "                \"mae\": mean_absolute_error(y_true_quantum, y_pred_quantum),\n",
    "                \"rmse\": mean_squared_error(y_true_quantum, y_pred_quantum, squared=False),\n",
    "                \"r2\": r2_score(y_true_quantum, y_pred_quantum),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    search_results.append(\n",
    "        {\n",
    "            **params,\n",
    "            \"mean_mae\": np.nanmean([metrics[\"mae\"] for metrics in fold_metrics]),\n",
    "            \"std_mae\": np.nanstd([metrics[\"mae\"] for metrics in fold_metrics]),\n",
    "            \"mean_rmse\": np.nanmean([metrics[\"rmse\"] for metrics in fold_metrics]),\n",
    "            \"std_rmse\": np.nanstd([metrics[\"rmse\"] for metrics in fold_metrics]),\n",
    "            \"mean_r2\": np.nanmean([metrics[\"r2\"] for metrics in fold_metrics]),\n",
    "            \"std_r2\": np.nanstd([metrics[\"r2\"] for metrics in fold_metrics]),\n",
    "        }\n",
    "    )\n",
    "\n",
    "search_results_df = (\n",
    "    pd.DataFrame(search_results)\n",
    "    .sort_values(\"mean_mae\", ascending=True)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "search_results_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}